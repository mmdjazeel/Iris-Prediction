{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(data.data, columns= data.feature_names), pd.DataFrame(data.target, columns= ['target'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop('target', axis=1).values, df.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Kfold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=6, min_samples_split=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334 0.059999999999999984\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    \n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv =cross_val_score(estimator=rf_clf, X=X, y=y, scoring='accuracy', cv=10, n_jobs=-1, verbose=1)\n",
    "rf_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = cross_val_predict(estimator=rf_clf, X=X, y=y, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_clf = ExtraTreesClassifier(n_estimators=100, max_depth=10, min_samples_leaf=5, min_samples_split=4, bootstrap=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666666 0.033333333333333326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    \n",
    "    xt_clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9533333333333334"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_cv =cross_val_score(estimator=xt_clf, X=X, y=y, scoring='accuracy', cv=10, n_jobs=-1, verbose=1)\n",
    "xt_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_pred = cross_val_predict(estimator=xt_clf, X=X, y=y, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_clf = GradientBoostingClassifier(n_estimators=1000, max_depth=10, min_samples_leaf=5, min_samples_split=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1         125.3093            3.99s\n",
      "         2         106.9426            3.99s\n",
      "         3          92.0511            3.99s\n",
      "         4          79.9348            3.98s\n",
      "         5          69.7843            3.98s\n",
      "         6          61.1890            4.64s\n",
      "         7          53.9747            5.11s\n",
      "         8          47.7660            5.46s\n",
      "         9          42.5132            5.29s\n",
      "        10          37.8211            5.15s\n",
      "        20          13.0282            4.12s\n",
      "        30           5.1219            3.36s\n",
      "        40           2.2403            2.98s\n",
      "        50           1.0361            2.66s\n",
      "        60           0.4629            2.51s\n",
      "        70           0.2340            2.34s\n",
      "        80           0.1289            2.16s\n",
      "        90           0.0694            2.14s\n",
      "       100           0.0374            2.09s\n",
      "       200           0.0176            1.28s\n",
      "       300           0.0176            0.92s\n",
      "       400           0.0176            0.73s\n",
      "       500           0.0176            0.58s\n",
      "       600           0.0176            0.58s\n",
      "       700           0.0176            0.50s\n",
      "       800           0.0176            0.36s\n",
      "       900           0.0176            0.17s\n",
      "      1000           0.0176            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.4780            4.00s\n",
      "         2         105.7754            6.01s\n",
      "         3          90.7067            5.33s\n",
      "         4          78.3432            4.98s\n",
      "         5          68.1828            5.58s\n",
      "         6          59.6416            5.31s\n",
      "         7          52.4072            5.11s\n",
      "         8          46.1612            5.46s\n",
      "         9          40.8293            5.29s\n",
      "        10          36.2075            5.15s\n",
      "        20          11.8169            4.12s\n",
      "        30           4.3057            3.88s\n",
      "        40           1.7286            3.36s\n",
      "        50           0.7993            3.04s\n",
      "        60           0.3794            2.76s\n",
      "        70           0.1844            2.55s\n",
      "        80           0.1025            2.39s\n",
      "        90           0.0545            2.27s\n",
      "       100           0.0327            2.16s\n",
      "       200           0.0173            1.33s\n",
      "       300           0.0173            1.07s\n",
      "       400           0.0173            1.09s\n",
      "       500           0.0173            0.89s\n",
      "       600           0.0173            0.67s\n",
      "       700           0.0173            0.53s\n",
      "       800           0.0173            0.37s\n",
      "       900           0.0173            0.20s\n",
      "      1000           0.0173            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.9003           12.00s\n",
      "         2         106.3372            7.98s\n",
      "         3          91.5202            6.65s\n",
      "         4          79.2120            7.97s\n",
      "         5          69.1091            7.16s\n",
      "         6          60.6322            7.95s\n",
      "         7          53.4304            7.38s\n",
      "         8          47.2931            6.94s\n",
      "         9          41.9987            7.05s\n",
      "        10          37.4605            6.73s\n",
      "        20          12.6286            6.27s\n",
      "        30           4.8025            5.82s\n",
      "        40           1.9865            4.90s\n",
      "        50           0.8463            4.71s\n",
      "        60           0.3752            4.45s\n",
      "        70           0.1818            4.62s\n",
      "        80           0.0953            4.46s\n",
      "        90           0.0524            4.53s\n",
      "       100           0.0295            4.50s\n",
      "       200           0.0187            3.01s\n",
      "       300           0.0187            2.30s\n",
      "       400           0.0187            1.73s\n",
      "       500           0.0187            1.35s\n",
      "       600           0.0187            0.99s\n",
      "       700           0.0187            0.69s\n",
      "       800           0.0187            0.43s\n",
      "       900           0.0187            0.20s\n",
      "      1000           0.0187            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.9055            0.00s\n",
      "         2         106.4452            2.00s\n",
      "         3          91.5666            2.66s\n",
      "         4          79.3546            1.99s\n",
      "         5          69.1954            2.39s\n",
      "         6          60.5771            3.32s\n",
      "         7          53.3390            3.40s\n",
      "         8          47.1045            2.98s\n",
      "         9          41.8222            3.08s\n",
      "        10          37.1566            3.17s\n",
      "        20          11.9989            2.94s\n",
      "        30           4.1589            2.85s\n",
      "        40           1.5663            2.98s\n",
      "        50           0.5978            2.81s\n",
      "        60           0.2378            2.69s\n",
      "        70           0.1047            2.50s\n",
      "        80           0.0514            2.39s\n",
      "        90           0.0288            2.43s\n",
      "       100           0.0205            2.30s\n",
      "       200           0.0205            1.50s\n",
      "       300           0.0205            1.73s\n",
      "       400           0.0205            1.45s\n",
      "       500           0.0205            1.19s\n",
      "       600           0.0205            0.92s\n",
      "       700           0.0205            0.66s\n",
      "       800           0.0205            0.41s\n",
      "       900           0.0205            0.19s\n",
      "      1000           0.0205            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.6518            7.99s\n",
      "         2         106.0692            5.99s\n",
      "         3          91.0792            5.32s\n",
      "         4          78.7697            5.97s\n",
      "         5          68.1969            4.77s\n",
      "         6          59.3271            4.64s\n",
      "         7          51.8307            4.54s\n",
      "         8          45.4563            4.97s\n",
      "         9          40.1410            4.84s\n",
      "        10          35.4513            4.36s\n",
      "        20          11.4331            3.53s\n",
      "        30           3.8790            2.98s\n",
      "        40           1.4016            2.69s\n",
      "        50           0.5584            2.43s\n",
      "        60           0.2177            2.32s\n",
      "        70           0.1017            2.18s\n",
      "        80           0.0535            2.07s\n",
      "        90           0.0296            1.98s\n",
      "       100           0.0193            1.91s\n",
      "       200           0.0179            1.30s\n",
      "       300           0.0179            1.39s\n",
      "       400           0.0179            1.27s\n",
      "       500           0.0179            1.06s\n",
      "       600           0.0179            0.82s\n",
      "       700           0.0179            0.60s\n",
      "       800           0.0179            0.39s\n",
      "       900           0.0179            0.18s\n",
      "      1000           0.0179            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.5542            4.00s\n",
      "         2         105.9118            3.99s\n",
      "         3          90.8864            3.99s\n",
      "         4          78.5587            3.98s\n",
      "         5          67.9228            3.98s\n",
      "         6          59.0217            3.98s\n",
      "         7          51.6066            3.97s\n",
      "         8          45.1894            3.97s\n",
      "         9          39.7945            3.96s\n",
      "        10          35.0601            3.96s\n",
      "        20          11.0708            3.14s\n",
      "        30           3.8412            2.85s\n",
      "        40           1.5715            2.50s\n",
      "        50           0.7186            2.36s\n",
      "        60           0.3594            2.26s\n",
      "        70           0.1947            2.13s\n",
      "        80           0.1052            2.02s\n",
      "        90           0.0566            1.90s\n",
      "       100           0.0330            1.84s\n",
      "       200           0.0158            1.22s\n",
      "       300           0.0158            0.91s\n",
      "       400           0.0158            0.89s\n",
      "       500           0.0158            0.87s\n",
      "       600           0.0158            0.75s\n",
      "       700           0.0158            0.54s\n",
      "       800           0.0158            0.34s\n",
      "       900           0.0158            0.16s\n",
      "      1000           0.0158            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.8398            4.00s\n",
      "         2         106.3852            2.00s\n",
      "         3          91.4489            2.66s\n",
      "         4          79.2056            2.99s\n",
      "         5          69.0189            2.39s\n",
      "         6          60.4275            2.65s\n",
      "         7          52.9299            2.84s\n",
      "         8          46.4932            2.48s\n",
      "         9          40.9901            2.65s\n",
      "        10          36.2745            2.77s\n",
      "        20          11.0368            3.92s\n",
      "        30           3.5899            4.27s\n",
      "        40           1.3562            3.74s\n",
      "        50           0.5243            3.34s\n",
      "        60           0.2017            3.01s\n",
      "        70           0.0937            2.87s\n",
      "        80           0.0454            2.76s\n",
      "        90           0.0210            2.75s\n",
      "       100           0.0201            2.74s\n",
      "       200           0.0201            2.22s\n",
      "       300           0.0201            1.91s\n",
      "       400           0.0201            1.48s\n",
      "       500           0.0201            1.28s\n",
      "       600           0.0201            1.01s\n",
      "       700           0.0201            0.79s\n",
      "       800           0.0201            0.50s\n",
      "       900           0.0201            0.24s\n",
      "      1000           0.0201            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.9561            0.00s\n",
      "         2         106.5842            6.00s\n",
      "         3          91.7401            5.31s\n",
      "         4          79.5317            5.97s\n",
      "         5          69.3573            8.75s\n",
      "         6          60.4699            7.95s\n",
      "         7          53.2169            8.51s\n",
      "         8          46.7844            8.43s\n",
      "         9          41.4879            8.81s\n",
      "        10          36.9291            8.31s\n",
      "        20          12.1228            7.05s\n",
      "        30           4.5426            5.82s\n",
      "        40           1.9549            5.57s\n",
      "        50           0.9115            5.17s\n",
      "        60           0.4417            4.64s\n",
      "        70           0.2068            4.25s\n",
      "        80           0.1260            3.91s\n",
      "        90           0.0735            3.64s\n",
      "       100           0.0478            3.38s\n",
      "       200           0.0184            2.08s\n",
      "       300           0.0184            1.47s\n",
      "       400           0.0184            1.18s\n",
      "       500           0.0184            1.16s\n",
      "       600           0.0184            0.96s\n",
      "       700           0.0184            0.71s\n",
      "       800           0.0184            0.45s\n",
      "       900           0.0184            0.21s\n",
      "      1000           0.0184            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.9146            7.88s\n",
      "         2         106.3701            5.95s\n",
      "         3          91.5620            5.28s\n",
      "         4          79.4084            5.96s\n",
      "         5          69.1701            5.55s\n",
      "         6          60.6809            5.28s\n",
      "         7          53.4808            5.09s\n",
      "         8          47.3517            4.45s\n",
      "         9          42.0601            4.39s\n",
      "        10          37.5241            4.35s\n",
      "        20          12.5475            3.33s\n",
      "        30           4.6689            2.84s\n",
      "        40           1.8563            2.69s\n",
      "        50           0.7866            2.51s\n",
      "        60           0.3479            2.38s\n",
      "        70           0.1656            2.23s\n",
      "        80           0.0902            2.07s\n",
      "        90           0.0514            1.94s\n",
      "       100           0.0292            1.84s\n",
      "       200           0.0171            1.22s\n",
      "       300           0.0171            0.91s\n",
      "       400           0.0171            0.70s\n",
      "       500           0.0171            0.56s\n",
      "       600           0.0171            0.43s\n",
      "       700           0.0171            0.38s\n",
      "       800           0.0171            0.29s\n",
      "       900           0.0171            0.15s\n",
      "      1000           0.0171            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         124.9146            3.88s\n",
      "         2         106.3678            3.95s\n",
      "         3          91.5579            3.95s\n",
      "         4          79.2588            3.95s\n",
      "         5          69.1651            3.16s\n",
      "         6          60.7002            3.30s\n",
      "         7          53.5004            2.82s\n",
      "         8          47.3715            2.96s\n",
      "         9          42.0801            3.07s\n",
      "        10          37.5442            3.16s\n",
      "        20          12.4735            2.54s\n",
      "        30           4.6437            2.71s\n",
      "        40           1.9615            3.26s\n",
      "        50           0.9222            3.80s\n",
      "        60           0.4174            3.95s\n",
      "        70           0.2059            4.04s\n",
      "        80           0.1135            4.00s\n",
      "        90           0.0640            4.04s\n",
      "       100           0.0411            4.03s\n",
      "       200           0.0164            2.94s\n",
      "       300           0.0164            2.33s\n",
      "       400           0.0164            1.75s\n",
      "       500           0.0164            1.31s\n",
      "       600           0.0164            0.96s\n",
      "       700           0.0164            0.65s\n",
      "       800           0.0164            0.41s\n",
      "       900           0.0164            0.19s\n",
      "      1000           0.0164            0.00s\n",
      "0.9666666666666666 0.033333333333333326\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    \n",
    "    gbc_clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_cv =cross_val_score(estimator=gbc_clf, X=X, y=y, scoring='accuracy', cv=10, n_jobs=-1, verbose=1)\n",
    "gbc_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_pred = cross_val_predict(estimator=gbc_clf, X=X, y=y, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_clf = AdaBoostClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666666 0.033333333333333326\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "\n",
    "    y_train, y_test = y[train_index], y[test_index] \n",
    "    \n",
    "    abc_clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = rf_clf.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, pred)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_cv =cross_val_score(estimator=abc_clf, X=X, y=y, scoring='accuracy', cv=10, n_jobs=-1, verbose=1)\n",
    "abc_cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc_pred = cross_val_predict(estimator=abc_clf, X=X, y=y, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.stack([rf_pred, xt_pred, gbc_pred, abc_pred, df.target.values], axis=1), columns=['rf', 'xt', 'gbc', 'abc', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred, y_pred = pred_df.drop('target', axis=1).values, pred_df.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_pred_clf = GradientBoostingClassifier(learning_rate=0.05, n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.05, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_pred_clf.fit(X_pred, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_stack_pred = gbc_pred_clf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, gbc_stack_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
